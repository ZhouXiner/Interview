ORB_SLAM有三个主要线程,Tracking + LocalMapping + Loop Closing

Tracking:
1.提取特征点
采用的是ORB角点，难点如下：
a.如何做的均匀化
金字塔(8层)，每一层都限制了数量，然后采用了四叉树来约束每个小区域的点数量
b.所谓角度对称性
计算角度时，ORB是在一个圆形区域进行的，构建了一个对称的圆形
然后以特征点为圆心，像素作为权重计算重心，重心和中心的连线就是方向
c.patch的含义
是Brief特征中需要用到的512个随机点，直接给给出了在31*31领域中的坐标，
可以直接找到
可以参考：
https://blog.csdn.net/saber_altolia/article/details/52623513

2.初始化
提取一定数量的点后，利用８点法计算F,H,然后计算两个score,其实就是看重投影误差
然后选择合适的初始化矩阵进行初始化（这里利用的描述子进行匹配，之后都是BOW）
初始化完成后，进行三角化(也是解的svd)得到一些地图点，然后进行深度初始化，注意
三角化只有在检测到有平移的时候进行
双目和RGB_D不需要，可以直接找有深度的点初始化，不需要两帧，也不需要联立

３.tracking
tracking流程：
https://www.notion.so/ORB-tracking-0e9802267de14c71929896e3b760a746
这个说的很清楚：https://blog.csdn.net/qq_20123207/article/details/82587130
1.假设匀速运动　　2.关键帧tracking 　3.当lost的时候，进行重定位(Epnp)
如果不满足匀速运动的条件(速度为０，匹配太少，ID相差大，则用２)
如果失败，就用3
lost条件：两帧之间match点太少，此时扩大上一帧的地图点投影范围，如果还失败就lost
匀速运动模型就直接重投影，得到两帧之间的error，BA优化
关键帧tracking,利用BOW向量进行特征点匹配，再进行重投影优化
关于BOW向量用于tracking:https://blog.csdn.net/KYJL888/article/details/102588059
也就是说ORB中维护了一个feature的词袋，用于匹配，每个描述子对应一个单词
匹配时采用了正向匹配和逆向匹配两种，进行加速
正向匹配：用第二层或者第三层作为父节点进行匹配(记录frame访问了哪些node)
对每个frame,都记录这个信息:描述子对应的Bow中的node编号和对应的features
这样在匹配时，如果两个frame都访问了同一个node，就把对应的features都拿出来看看哪些feature能够匹配的上(描述子距离)

逆向匹配：用于回环和重定位(反向索引记录每个叶节点对应的图像编号)


即对于这个字典，有两种，一种是从图片查单词（每张图片有哪些单词，
以及单词对应的图片上特征点的具体编号）
另一种是从单词查图片（每个单词在哪些图片被观测到，以及这个单词在这张图片的权重）

运动模型和关键帧模型的区别：
(1)、运动模型跟踪利用上一帧姿态和速度来初始化当前帧位姿，参考帧模型仅仅使用上一帧位姿来初始化当前帧位姿。
(2)、运动模型跟踪利用投影匹配，参考帧模型使用词袋匹配。
(3)、运动模型跟踪需要考虑是否为纯跟踪模式（判断mtach点是否足够时，onlytracking的条件放宽），而参考关键帧跟踪则不需要。
(4)、运动模型跟踪与上一帧进行匹配，而参考关键帧跟踪则是与参考关键帧进行匹配。

重定位(三次定位，三次优化)：
1.根据词袋，找到候选关键帧，并得到匹配点数量，删除数量少的关键帧
2.根据pnp求解位姿，根据是否达到最大迭代次数剔除一部分候选帧
3.匹配的地图点剔除外点，进行位姿优化
4.位姿优化之后，剔除当前帧地图点中的外点。若此时内点数较少，不能满足要求，
  则进行候选关键帧与当前帧之间的投影匹配，以此来增加匹配点数量。（第二次匹配）
5.优化后的内点数与投影匹配得到的匹配点数之和 大于 阈值，
  则再次进行优化（第二次优化）。
6.第二次优化后内点数若是还不满足要求，那么就再次通过缩小窗口
  进行投影匹配（第三次匹配）。
7.第二次优化后的内点数与第三次投影匹配得到的匹配点数之和 大于 阈值，
  则进行最终优化（第三次优化）。
最后，根据优化后的内点数判定重定位是否成功。

Tracking时如何选取关键帧？
时间上够长，匹配质量够好，空间上够长

Tracking中的localmap
tracking后，记录下当前帧和其他帧的共视关系，然后将其他帧和他们的essential graph
中的相关帧都记录下来，这样就找到了当前帧的所有邻居然后再记录下这些邻
能够看到哪些match的地图点(也Update新的)，然后基于这些map点做一个局部的BA

ORB中维护的几个图：
1）Covisibility Graph：共视图，是一个无向有权图（Graph），这个概念最早
来自2010的文章[Closing Loops Without Places]。该图中每个顶点就是关键帧
，如果两个关键帧有相同的地图点（即它们有共视点），就把这两个顶点连接起来，
连接边的权重就是两个关键帧共享的3D点的个数。局部BA优化依赖的就是一个局部的
共视图，全局BA优化依赖的就是一个全局的共视图，总之共视图在ORB SLAM2中用
得很多。
2）Essential Graph：为了在优化阶段减小计算量，ORB-SLAM2作者提出了
Essential Graph的概念，主要用它来进行全局位姿优化。它是共视图的子集，
即Covisibity Graph的最小生成树（MST）。该图中顶点是关键帧，但只连接某
个关键帧和与之拥有最多共享的地图点的关键帧，这样能够连接所有的顶点，
但是边会减少很多。只有地图点>100才会连接，size在上下之间
3）Spanning Graph：生成树，是代价最小的全联通图，Essential Graph
就是基于Sanning Graph生成的

Local Mapping:
https://www.cnblogs.com/liumantang/p/11830376.html
tracking中，我们经历了初始化，三种方式的tracking，lm的BA(这里是指当构建local map后，会在local map中搜索当前帧能够匹配上的地图点，然后再pose optimization)
和关键帧的选择，
终于到了LM
Local Mapping主要做以下几件事：
1.处理新的关键帧
计算关键帧的Bow,将Tracking中得到的地图点绑定到当前关键帧中
并将关键帧加入到图中
2.地图点检查删除
当前关键帧加入后，我们也加入了地图点，被看到很多次的map点被保留
少的就删除
3.生成新的地图点
与共视帧生成新的map,三角化，然后将点融合
如何融合：
找到当前帧的共视帧以及这些共视帧的共视帧，将他们的地图点投影到当前关键帧
如果描述子小于阈值，说明可以融合，然后将共视关系多的代替共视关系小的
4.Local BA 
基于共视图(convibility graph)对当前帧的Local进行BA
5.关键帧删除
共视关系太强的关键帧，删除
关键帧检测到的90%的地图点，在其他不少于三个具有相同或更精确尺度的关键帧里面
都被检测到，就认定该关键帧冗余（该关键帧的存在提供的地图点观测信息有限），并剔除。

关于新的地图点需要维护的信息
a设置观察到该地图点的关键帧，
b计算地图点的最优描述子，
c计算地图点的平均观测方向和深度范围

关于插入关键帧和插入地图点：
在初始化时可以插入关键帧和地图点
关键帧到LM中可以插入关键帧，也可以插入地图点

Loop Detecion And Correction
根据BoW筛选出一些候选帧
然后求解sim3，如果优化后匹配地图点很多，就不再找其他候选帧，如果效果不好
就继续匹配其他关键帧，直到找到比较好的
找到比较好的之后，就基于优化结果更新位姿
Loop Fusion阶段，第一步是融合重复的地图点，并且在covisibility graph里补上
回环的那条边。然后根据之前计算出的新关键帧和回环关键帧的变换，调整新关键帧
及周围关键帧的位置姿态，这样回环的两头就基本对齐了。
然后再把回环关键帧附近的地图点投影到新关键帧，把匹配上的地图点融合起来。
然后基于基本图进行全局位姿优化

比较好的对loop closure解释：
https://www.notion.so/bd6c965c651241e0a3fc87c791fda9d8
1.基于ransac，得到与候选帧之间的sim3 pose
2.重投影，优化sim3
3.更新local map中的pose 
4.将essential graph和最小生成树(确保整个地图都被优化)一起进行gba

